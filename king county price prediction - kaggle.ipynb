{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kc_house_data.csv')\n",
    "df=pd.DataFrame(df)\n",
    "df['date']  = pd.to_datetime(df['date'])\n",
    "year = df['date'].dt.year\n",
    "for x in range(21613): \n",
    "    if df['yr_renovated'][x] == 0:\n",
    "        yr_actual_point = df['yr_built']\n",
    "    else:\n",
    "        yr_actual_point = df['yr_renovated']\n",
    "df['age'] = year - yr_actual_point \n",
    "df['is_renovated']=df['yr_renovated'].apply(lambda x : 0 if x==0 else 1)\n",
    "df = df[['sqft_living', 'floors', 'bedrooms', 'bathrooms','grade','is_renovated','waterfront','view','zipcode','age','price']]\n",
    "df = pd.get_dummies(df,columns=['zipcode'])\n",
    "X = df[df.columns.difference(['price','zipcode_98001'])]\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gvsva\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152160.96783104105"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182232.62158711778"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred=dt.predict(X_test)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139991.565802109"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(criterion='mse',n_jobs=1)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146613.83602468873"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xg= XGBRegressor()\n",
    "xg.fit(X_train,y_train)\n",
    "y_pred=xg.predict(X_test)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A host of Scikit-learn models\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# # from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# # from sklearn.neighbors import KNeighborsClassifier\n",
    "# # from sklearn.neural_network import MLPClassifier\n",
    "# # from sklearn.kernel_approximation import Nystroem\n",
    "# # from sklearn.kernel_approximation import RBFSampler\n",
    "# # from sklearn.pipeline import make_pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     33
    ]
   },
   "outputs": [],
   "source": [
    "# def get_models():\n",
    "#     \"\"\"Generate a library of base learners.\"\"\"\n",
    "# #     SEED = 123\n",
    "# #     nb = GaussianNB()\n",
    "# #     svc = SVC(C=100, probability=True)\n",
    "# #     knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# #     lr = LogisticRegression(C=100, random_state=SEED)\n",
    "# #     nn = MLPClassifier((80, 10), early_stopping=False, random_state=SEED)\n",
    "# #     gb = GradientBoostingClassifier(n_estimators=100, random_state=SEED)\n",
    "# #     rf = RandomForestClassifier(n_estimators=10, max_features=3, random_state=SEED)\n",
    "#     regressor = LinearRegression()\n",
    "#     rf = RandomForestRegressor(max_depth=15)    \n",
    "#     xg= XGBRegressor()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     models = {'linear regression' : regressor,\n",
    "#              'random forest': rf,\n",
    "#              'xgboost': xg}\n",
    "        \n",
    "# #     models = {'svm': svc,\n",
    "# #               'knn': knn,\n",
    "# #               'naive bayes': nb,\n",
    "# #               'mlp-nn': nn,\n",
    "# #               'random forest': rf,\n",
    "# #               'gbm': gb,\n",
    "# #               'logistic': lr,\n",
    "# #               }\n",
    "\n",
    "#     return models\n",
    "\n",
    "\n",
    "# def train_predict(model_list):\n",
    "#     \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "#     P = np.zeros((y_test.shape[0], len(model_list)))\n",
    "#     P = pd.DataFrame(P)\n",
    "\n",
    "#     print(\"Fitting models.\")\n",
    "#     cols = list()\n",
    "#     for i, (name, m) in enumerate(models.items()):\n",
    "#         print(\"%s...\" % name, end=\" \", flush=False)\n",
    "#         m.fit(X_train, y_train)\n",
    "#         P.iloc[:, i] = m.predict(X_test)\n",
    "#         cols.append(name)\n",
    "#         print(\"done\")\n",
    "\n",
    "#     P.columns = cols\n",
    "#     print(\"Done.\\n\")\n",
    "#     return P\n",
    "\n",
    "\n",
    "# def score_models(P, y):\n",
    "#     \"\"\"Score model in prediction DF\"\"\"\n",
    "#     print(\"Scoring models.\")\n",
    "#     for m in P.columns:\n",
    "#         score = np.sqrt(mean_squared_error(y, P.loc[:, m]))\n",
    "#         print(\"%-26s: %.3f\" % (m, score))\n",
    "#     print(\"Done.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = get_models()\n",
    "# P = train_predict(models)\n",
    "# score_models(P, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119030.4120771039"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor(alpha= 0.9,learning_rate= 0.1,loss='ls',max_depth=15,n_estimators=100,min_samples_split=30,max_features=10,random_state=0)\n",
    "gb.fit(X_train,y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k- fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8540109306988176"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = gb, X = X, y = y, cv = 10)\n",
    "accuracies.mean()\n",
    "# accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters = [{'loss':['ls'],'learning_rate':[0.1],'n_estimators':[100],\n",
    "#               'max_depth':[10],'alpha':[0.9]},\n",
    "#              {'loss':['ls'],'learning_rate':[0.1],'n_estimators':[100],\n",
    "#               'max_depth':[15],'alpha':[0.9]}]\n",
    "# grid_search = GridSearchCV(estimator = gb,\n",
    "#                            param_grid = parameters,\n",
    "#                            cv = 10,\n",
    "#                            n_jobs = -1)\n",
    "# grid_search = grid_search.fit(X_train, y_train)\n",
    "# best_accuracy = grid_search.best_score_\n",
    "# best_parameters = grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
